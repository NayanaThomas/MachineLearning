{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading test and train data\n",
    "datatrain = pd.read_csv('bikeRentalHourlyTrain.csv', header=0, na_values=np.NaN, sep=',')\n",
    "datatest = pd.read_csv('bikeRentalHourlyTest.csv', header=0, na_values=np.NaN, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing unwanted columns\n",
    "datatrain = datatrain.drop(datatrain.columns[[0, 1, 2, 11, 15, 16]], axis=1)\n",
    "datatest = datatest.drop(datatest.columns[[0, 1, 2, 11, 15, 16]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to clean the dataset\n",
    "#based on the datatype of the attribute, the NaN values are replaced with standard values\n",
    "#if datatype is object, replaced with empty string\n",
    "#if datatype is int64, replaced with rounded off mean value\n",
    "#if datatype is float64, replaced with meanvalue\n",
    "def cleanDataFrame(data):\n",
    "    for i in range(0, data.shape[1]):\n",
    "        colValues = data.iloc[:,i:i+1].iloc[:,0]\n",
    "        colType = data.iloc[:,i:i+1].iloc[:,0].dtype\n",
    "        if colType == 'int64':\n",
    "            data.iloc[:,i:i+1] = data.iloc[:,i:i+1].fillna(round(colValues.mean()))\n",
    "        elif colType == 'float64':\n",
    "            data.iloc[:,i:i+1] = data.iloc[:,i:i+1].fillna(colValues.mean())        \n",
    "        elif colType == 'object':\n",
    "            data.iloc[:,i:i+1] = data.iloc[:,i:i+1].fillna('')            \n",
    "#calling the methods on train and test data\n",
    "cleanDataFrame(datatrain)\n",
    "cleanDataFrame(datatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to create dummy variables\n",
    "def changeToCategoryType(data):\n",
    "    for header in data.columns:\n",
    "        #if header!='cnt':\n",
    "            data[header] = data[header].astype('category').cat.codes\n",
    "#calling the methods on train and test data\n",
    "changeToCategoryType(datatest)\n",
    "changeToCategoryType(datatrain)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scaling the input data\n",
    "#makes the algorithm converge faster\n",
    "#We use a built in function to do this.\n",
    "scaler = StandardScaler()\n",
    "#Splitting original train data to feature list and target list.\n",
    "X_train = datatrain.iloc[:,0:11]\n",
    "y_train = datatrain.iloc[:,11:12].iloc[:,0]\n",
    "scaler.fit(X_train)\n",
    "#Splitting original test data to feature list and target list.\n",
    "X_test = datatest.iloc[:,0:11]\n",
    "y_test = datatest.iloc[:,11:12].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now use the scaler to scale both test and train predictors\n",
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to build neural network and print MSE of both train and test data\n",
    "def createNeuralNetwork():\n",
    "    print('Neural Network Metrics')\n",
    "    #Here we configure the architecure. These are hidden layers only\n",
    "    #The function will automatically create input nodes (one for each variable) and \n",
    "    #one output node (for the target value)\n",
    "    MLPregr = MLPRegressor(hidden_layer_sizes=(15, 15, 15), max_iter=2000)\n",
    "    #Fit the model and learn the weights\n",
    "    MLPregr.fit(X_train,y_train)\n",
    "    #Let's now use the model to predict the target:\n",
    "    predicted_train = MLPregr.predict(X_train)\n",
    "    predicted_test = MLPregr.predict(X_test)\n",
    "    print(\"Training Mean squared error: %.2f\" % mean_squared_error(y_train, predicted_train))\n",
    "    print(\"Test Mean squared error: %.2f\" % mean_squared_error(y_test, predicted_test))\n",
    "    \n",
    "    #5-fold cross validation for test data set\n",
    "    #We provide train/test indices to split data in test sets. \n",
    "    #We split the dataset into 5 consecutive folds (without shuffling by default).\n",
    "    #Each fold is then used once as a validation while the 4 remaining folds form the training set.\n",
    "    print(\"Metrics after 5-fold CV\")\n",
    "    kf = KFold(n_splits=5)\n",
    "    kf.get_n_splits(X_train)\n",
    "    MSE = 0.0\n",
    "    for train_index, test_index in kf.split(X_test):\n",
    "        MLPregr.fit(X_test[train_index],y_test[train_index])\n",
    "        predictions = MLPregr.predict(X_test[test_index])\n",
    "        MSE += sum((predictions - y_test[test_index])**2)/len(predictions)\n",
    "    print(\"Test Mean squared error: %.2f\" % (MSE/5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Metrics\n"
     ]
    }
   ],
   "source": [
    "#creating the neural network for the data set\n",
    "createNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to create linear regression model and print MSE of test and train data.\n",
    "def createRegression():\n",
    "    print('Linear Regression Metrics:')\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X_train, y_train)\n",
    "    predicted_train = regr.predict(X_train)\n",
    "    print(\"Training Mean squared error: %.2f\" % mean_squared_error(y_train, predicted_train))\n",
    "    predicted_test = regr.predict(X_test)\n",
    "    print(\"Test Mean squared error: %.2f\" % mean_squared_error(y_test, predicted_test))\n",
    "    \n",
    "    #5-fold cross validation.\n",
    "    #We provide train/test indices to split data in test sets. \n",
    "    #We split the dataset into 5 consecutive folds (without shuffling by default).\n",
    "    #Each fold is then used once as a validation while the 4 remaining folds form the training set. \n",
    "    print(\"Metrics after 5-fold CV\")\n",
    "    kf = KFold(n_splits=5)\n",
    "    kf.get_n_splits(X_test)\n",
    "    MSE = 0.0\n",
    "    for train_index, test_index in kf.split(X_test):\n",
    "        regr.fit(X_test[train_index],y_test[train_index])\n",
    "        predictions = regr.predict(X_test[test_index])\n",
    "        MSE += sum((predictions - y_test[test_index])**2)/len(predictions)\n",
    "    print(\"Test Mean squared error: %.2f\" % (MSE/5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "Training Mean squared error: 19411.97\n",
      "Test Mean squared error: 16853.71\n",
      "Metrics after 5-fold CV\n",
      "Test Mean squared error: 16729.32\n"
     ]
    }
   ],
   "source": [
    "#creating the linear regression model for the data set\n",
    "createRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Rigression Ridge Metrics\n",
      "Mean squared error: 16853.67\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's try Ridge and Lasso. We'll do Ridge first.\n",
    "regrRidge = linear_model.Ridge(alpha = 1)\n",
    "regrRidge.fit(X_train, y_train)\n",
    "ridgePredictions = regrRidge.predict(X_test)\n",
    "# The mean squared error\n",
    "print('Linear Rigression Ridge Metrics')\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, ridgePredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Lasso Metrics\n",
      "Mean squared error: 16852.24\n"
     ]
    }
   ],
   "source": [
    "# Not much of difference - seems all variables are important. We try Lasso ...\n",
    "regrLasso = linear_model.Lasso(alpha = .1)\n",
    "regrLasso.fit(X_train, y_train)\n",
    "lassoPredictions = regrLasso.predict(X_test)\n",
    "# The mean squared error\n",
    "print('Linear Regression Lasso Metrics')\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, lassoPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to build Radial SVM and print its mean squared error of both train and test data\n",
    "def createKNN():\n",
    "    print('KNN with k=8 Metrics')\n",
    "    KNN = KNeighborsRegressor(n_neighbors=8)\n",
    "    KNN.fit(X_train,y_train)\n",
    "    predicted_train = KNN.predict(X_train)\n",
    "    predicted_test = KNN.predict(X_test)\n",
    "    print(\"Training Mean squared error: %.2f\" % mean_squared_error(y_train, predicted_train))\n",
    "    print(\"Test Mean squared error: %.2f\" % mean_squared_error(y_test, predicted_test))  \n",
    "    \n",
    "    #5-fold cross validation.\n",
    "    #We provide train/test indices to split data in test sets. \n",
    "    #We split the dataset into 5 consecutive folds (without shuffling by default).\n",
    "    #Each fold is then used once as a validation while the 4 remaining folds form the training set.\n",
    "    print(\"Metrics after 5-fold CV\")\n",
    "    kf = KFold(n_splits=5)\n",
    "    kf.get_n_splits(X_test)\n",
    "    MSE = 0.0\n",
    "    for train_index, test_index in kf.split(X_test):\n",
    "        KNN = KNeighborsRegressor(n_neighbors=4)\n",
    "        KNN.fit(X_test[train_index],y_test[train_index])\n",
    "        predictions = KNN.predict(X_test[test_index])\n",
    "        MSE += sum((predictions - y_test[test_index])**2)/len(predictions)\n",
    "    print(\"Test Mean squared error: %.2f\" % (MSE/5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with k=8 Metrics\n",
      "Training Mean squared error: 8560.51\n",
      "Test Mean squared error: 9234.95\n",
      "Metrics after 5-fold CV\n",
      "Test Mean squared error: 12913.93\n"
     ]
    }
   ],
   "source": [
    "createKNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
